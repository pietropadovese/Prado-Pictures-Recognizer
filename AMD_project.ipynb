{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKUyrx3m/S7e0uqppzAc86",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pietropadovese/Prado-Pictures-Recognizer/blob/main/AMD_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtlBZdbjyYI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a205230-72f1-4218-af76-24599da8463c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting visualkeras\n",
            "  Downloading visualkeras-0.1.3-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (10.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from visualkeras) (1.26.4)\n",
            "Collecting aggdraw>=1.3.11 (from visualkeras)\n",
            "  Downloading aggdraw-1.3.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (655 bytes)\n",
            "Downloading visualkeras-0.1.3-py3-none-any.whl (16 kB)\n",
            "Downloading aggdraw-1.3.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.7/993.7 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aggdraw, visualkeras\n",
            "Successfully installed aggdraw-1.3.19 visualkeras-0.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install visualkeras\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from scipy.optimize import fsolve\n",
        "from math import exp\n",
        "\n",
        "from tensorflow.keras.layers import(\n",
        "    Conv2D,\n",
        "    Dense,\n",
        "    Flatten,\n",
        "    Add,\n",
        "    MaxPool2D,\n",
        "    AveragePooling2D,\n",
        "    GlobalAveragePooling2D,\n",
        "    BatchNormalization,\n",
        "    Dropout,\n",
        "    ReLU,\n",
        "    PReLU,\n",
        "    concatenate,\n",
        "  )\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import visualkeras\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Store the Data"
      ],
      "metadata": {
        "id": "jET1tDiQztRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download file from Kaggle\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"userdata.get('KAGGLE_USERNAME')\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"userdata.get('KAGGLE_KEY')\"\n",
        "!kaggle datasets download maparla/prado-museum-pictures\n",
        "!kaggle datasets download maparla/prado-museum-pictures -f prado.csv\n",
        "!unzip prado.csv.zip"
      ],
      "metadata": {
        "id": "LaJNQShLzz8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49308e6a-1e23-40dc-a6d0-5f211f32ecab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/maparla/prado-museum-pictures\n",
            "License(s): MIT\n",
            "Downloading prado-museum-pictures.zip to /content\n",
            "100% 24.9G/24.9G [22:54<00:00, 17.8MB/s]\n",
            "100% 24.9G/24.9G [22:54<00:00, 19.5MB/s]\n",
            "Dataset URL: https://www.kaggle.com/datasets/maparla/prado-museum-pictures\n",
            "License(s): MIT\n",
            "Downloading prado.csv.zip to /content\n",
            " 93% 17.0M/18.3M [00:02<00:00, 14.5MB/s]\n",
            "100% 18.3M/18.3M [00:02<00:00, 9.25MB/s]\n",
            "Archive:  prado.csv.zip\n",
            "  inflating: prado.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read teh csv file with url and info about images\n",
        "df = pd.read_csv(\"prado.csv\")\n",
        "df[\"work_id\"] = df['work_image_url'].apply(lambda x: x.split('/')[-1])\n",
        "col_to_keep = ['work_id', 'work_image_url', 'author']\n",
        "df = df[col_to_keep]"
      ],
      "metadata": {
        "id": "2FsGnHNB0jEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the most common authors\n",
        "values, counts = np.unique(df['author'], return_counts = True)\n",
        "count_df = pd.DataFrame({'author': values, 'count': counts})\n",
        "count_df = count_df.sort_values(by = 'count', ascending = False)\n",
        "authors = count_df['author'][1:6].values #skipping Anonimo\n",
        "authors = {author.split(\" \")[0] : author for author in authors}"
      ],
      "metadata": {
        "id": "oXszV9oh0t9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the painting of each author in a different folder\n",
        "zip_file_path = 'prado-museum-pictures.zip'\n",
        "os.makedirs('./extracted_images', exist_ok = True)\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "\n",
        "  namelist = [el.lstrip('images/images/') for el in zip_ref.namelist()]\n",
        "\n",
        "  for author, author_full_name in authors.items():\n",
        "\n",
        "    df_reduced = df[df['author'] == author_full_name]\n",
        "\n",
        "    os.makedirs(f'./Data/{author}', exist_ok = True)\n",
        "\n",
        "    for file in df_reduced['work_id'].unique():\n",
        "\n",
        "      if file in namelist:\n",
        "\n",
        "        extracted_path = zip_ref.extract(f'images/images/{file}', path = f'./extracted_images/')\n",
        "\n",
        "        new_name = os.path.join(f'./Data/{author}')\n",
        "\n",
        "        shutil.move(extracted_path, new_name)"
      ],
      "metadata": {
        "id": "iPQ6hqUh07SK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm prado-museum-pictures.zip"
      ],
      "metadata": {
        "id": "CQy9pxb31Nbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Load the Data for the models"
      ],
      "metadata": {
        "id": "Ga3bZl0_1Q64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb_folder = '/content/Data'\n",
        "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(gb_folder,\n",
        "                                                               label_mode=\"int\",\n",
        "                                                               color_mode=\"rgb\",\n",
        "                                                               batch_size=32,\n",
        "                                                               image_size=(224, 224),\n",
        "                                                               shuffle=True,\n",
        "                                                               seed=42,\n",
        "                                                               validation_split=0.1,\n",
        "                                                               subset=\"both\",\n",
        "                                                               labels=\"inferred\"\n",
        "                                                               )\n",
        "\n",
        "INPUT_SHAPE = (224, 224, 3)"
      ],
      "metadata": {
        "id": "rvBSoJgU1WKl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10385683-beb3-4805-a544-038b8a672b96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2058 files belonging to 5 classes.\n",
            "Using 1853 files for training.\n",
            "Using 205 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make sure to use buffered prefetching so we can yield data from disk without having I/O become blocking:\n",
        "- Dataset.cache: keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "- Dataset.prefetch: overlaps data preprocessing and model executing while training."
      ],
      "metadata": {
        "id": "GT_Slnsj1hMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "9Q76TcUh1aYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folders to save best model and metrics\n",
        "!mkdir model_saves\n",
        "!mkdir csv_logs\n",
        "!mkdir training_history\n",
        "!mkdir plots"
      ],
      "metadata": {
        "id": "qwYL3P501z1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a preporcessing step that will be used in all models\n",
        "\n",
        "def preprocessing(inputs):\n",
        "\n",
        "  X = tf.keras.layers.Rescaling(1./255)(inputs)\n",
        "\n",
        "  X = tf.keras.layers.RandomFlip(mode = \"horizontal\")(X)\n",
        "\n",
        "  X = tf.keras.layers.RandomRotation(factor = 0.2)(X)\n",
        "\n",
        "  X = tf.keras.layers.Lambda(function=tf.image.per_image_standardization,\n",
        "                           name=\"Per_image_standardisation\")(X)\n",
        "  return X"
      ],
      "metadata": {
        "id": "8381bb4L2HqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining class weights and output bias\n",
        "\n",
        "class_obs = np.array([1080, 446, 326, 290, 222])\n",
        "class_frequencies = class_obs / sum(class_obs)\n",
        "\n",
        "class_weights = {}\n",
        "\n",
        "for cls, freq in enumerate(class_obs):\n",
        "  class_weights[cls] = (1 / class_obs[cls]) * sum(class_obs) / len(class_obs)\n",
        "\n",
        "\n",
        "def eqn(x, frequency=class_frequencies):\n",
        "\n",
        "      sum_exp = sum([exp(x_i) for x_i in x])\n",
        "\n",
        "      return [exp(x[i])/sum_exp - frequency[i] for i in range(len(frequency))]\n",
        "\n",
        "output_bias = fsolve(func=eqn, x0=[0]*len(class_frequencies),).tolist()\n",
        "\n",
        "output_bias = tf.keras.initializers.Constant(output_bias)"
      ],
      "metadata": {
        "id": "ESK_RhP92jdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Creating the models"
      ],
      "metadata": {
        "id": "2WiImdWH2-nK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sequential:\n",
        "\n",
        "    def __init__(self, input_shape = (INPUT_SHAPE)):\n",
        "\n",
        "        self.inputs = tf.keras.Input(shape = input_shape)\n",
        "        self.model = self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "\n",
        "        X = preprocessing(self.inputs)\n",
        "\n",
        "        X = self._conv_block(X, 64, 2)\n",
        "\n",
        "        X = self._conv_block(X, 128, 2)\n",
        "\n",
        "        X = self._conv_block(X, 256, 3)\n",
        "\n",
        "        X = self._conv_block(X, 512, 3)\n",
        "\n",
        "        X = tf.keras.layers.Flatten()(X)\n",
        "\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        X = BatchNormalization()(X)\n",
        "        X = PReLU()(X)\n",
        "\n",
        "        X = tf.keras.layers.Dense(16, activation = 'relu')(X)\n",
        "        X = BatchNormalization()(X)\n",
        "        X = PReLU()(X)\n",
        "\n",
        "        X = tf.keras.layers.Dense(5, activation = 'softmax', kernel_initializer = \"HeNormal\", bias_initializer = output_bias)(X)\n",
        "\n",
        "        return tf.keras.Model(inputs = self.inputs, outputs = X)\n",
        "\n",
        "    def _conv_block(self, inputs, filters, repetitions, kernel_size = (3,3)):\n",
        "\n",
        "        for i in range(repetitions):\n",
        "\n",
        "            X = Conv2D(filters = filters,\n",
        "                        kernel_size = kernel_size,\n",
        "                        padding = 'same',\n",
        "                        kernel_initializer = \"HeNormal\",\n",
        "                        )(inputs)\n",
        "\n",
        "            X = BatchNormalization()(X)\n",
        "\n",
        "            X = ReLU()(X)\n",
        "\n",
        "        X = AveragePooling2D(pool_size = (2,2))(X)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def get_model(self):\n",
        "\n",
        "        return self.model"
      ],
      "metadata": {
        "id": "h-RBM25h3BBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet:\n",
        "\n",
        "    def __init__(self, input_shape = (INPUT_SHAPE)):\n",
        "\n",
        "        self.inputs = tf.keras.Input(shape = input_shape)\n",
        "        self.model = self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "\n",
        "        X = preprocessing(self.inputs)\n",
        "\n",
        "        X = self._conv_block(X, 64, 1)\n",
        "\n",
        "        X = self._identity_block(X, 64, layer_rep = 2, increase_dim = False)\n",
        "\n",
        "        X = self._identity_block(X, 128, layer_rep = 3, increase_dim = True)\n",
        "\n",
        "        X = self._identity_block(X, 256, layer_rep = 3, increase_dim = True)\n",
        "\n",
        "        X = self._identity_block(X, 512, layer_rep = 3, increase_dim = True)\n",
        "\n",
        "        X = tf.keras.layers.Flatten()(X)\n",
        "\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        X = BatchNormalization()(X)\n",
        "        X = PReLU()(X)\n",
        "\n",
        "        X = tf.keras.layers.Dense(16, activation = 'relu')(X)\n",
        "        X = BatchNormalization()(X)\n",
        "        X = PReLU()(X)\n",
        "\n",
        "        X = tf.keras.layers.Dense(5, activation = 'softmax', kernel_initializer = \"HeNormal\", bias_initializer = output_bias)(X)\n",
        "\n",
        "        return tf.keras.Model(inputs = self.inputs, outputs = X)\n",
        "\n",
        "\n",
        "    def _conv_block(self, inputs, filters, kernel_size = (3,3)):\n",
        "\n",
        "        X = Conv2D(filters = filters,\n",
        "                  kernel_size = kernel_size,\n",
        "                  padding = 'same',\n",
        "                  kernel_initializer = \"he_normal\",\n",
        "                  )(inputs)\n",
        "\n",
        "        X = BatchNormalization()(X)\n",
        "        X = ReLU()(X)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def _identity_block(self, inputs, filter, layer_rep, increase_dim):\n",
        "\n",
        "      \"\"\"\n",
        "      - layer_rep : number of convolutional layers\n",
        "      - increase_dim : boolean representing whether the input and the output have different dim\n",
        "      \"\"\"\n",
        "\n",
        "      # Save the input to add it back at the end\n",
        "      X_short = inputs\n",
        "      X = inputs\n",
        "\n",
        "      for i in range(layer_rep-1):\n",
        "        X = self._conv_block(X, filter)\n",
        "\n",
        "      # After this we need to add one more Conv and Batch before adding X_short and proceed with the activation\n",
        "\n",
        "      X = Conv2D(filters = filter,\n",
        "                kernel_size = 3,\n",
        "                padding = \"same\",\n",
        "                kernel_initializer = \"he_normal\"#,\n",
        "                )(X)\n",
        "\n",
        "      X = BatchNormalization()(X)\n",
        "\n",
        "      if increase_dim:\n",
        "\n",
        "        X_short = Conv2D(filters = filter,\n",
        "                kernel_size = 1,\n",
        "                padding = \"same\",\n",
        "                kernel_initializer = \"he_normal\"#,\n",
        "                #name = f'Conv2D_{index}'\n",
        "                )(X_short)\n",
        "\n",
        "        X_short = BatchNormalization()(X_short)\n",
        "\n",
        "      X = Add()([X, X_short])\n",
        "      X = ReLU()(X)\n",
        "      X = AveragePooling2D(pool_size = (2,2))(X)\n",
        "\n",
        "      return X\n",
        "\n",
        "    def get_model(self):\n",
        "\n",
        "        return self.model"
      ],
      "metadata": {
        "id": "vWX5cFFxIaoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DenseNet:\n",
        "\n",
        "    def __init__(self, input_shape = (INPUT_SHAPE)):\n",
        "\n",
        "        self.inputs = tf.keras.Input(shape = input_shape)\n",
        "        self.model = self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "\n",
        "        X = preprocessing(self.inputs)\n",
        "\n",
        "        X = Conv2D(64, 7, strides = 2, padding = 'same')(X)\n",
        "        X = MaxPool2D(3, strides = 2, padding = 'same')(X)\n",
        "\n",
        "        for repetition in [6,12,24,16]:\n",
        "\n",
        "            d = self._dense_block(X, repetition)\n",
        "            X = self._transition_block(d)\n",
        "\n",
        "        X = GlobalAveragePooling2D()(d)\n",
        "\n",
        "\n",
        "        X = tf.keras.layers.Dense(32, activation = 'relu')(X)\n",
        "        X = BatchNormalization()(X)\n",
        "        X = PReLU()(X)\n",
        "\n",
        "        X = tf.keras.layers.Dense(16, activation = 'relu')(X)\n",
        "        X = BatchNormalization()(X)\n",
        "        X = PReLU()(X)\n",
        "\n",
        "        X = tf.keras.layers.Dense(5, activation = 'softmax', kernel_initializer = \"HeNormal\", bias_initializer = output_bias)(X)\n",
        "\n",
        "        return tf.keras.Model(inputs = self.inputs, outputs = X)\n",
        "\n",
        "\n",
        "    def _conv_block(self, inputs, filters, kernel = 1):\n",
        "\n",
        "        X = Conv2D(filters = filters,\n",
        "               kernel_size = kernel,\n",
        "               padding = 'same',\n",
        "               kernel_initializer = \"he_normal\"\n",
        "               )(inputs)\n",
        "\n",
        "        X = BatchNormalization()(X)\n",
        "        X = ReLU()(X)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def _dense_block(self, X, repetitions, filters = 32):\n",
        "\n",
        "        for _ in range(repetitions):\n",
        "\n",
        "            y = self._conv_block(X, filters*4)\n",
        "            y = self._conv_block(y, filters, 3)\n",
        "            X = concatenate([y,X])\n",
        "\n",
        "        return X\n",
        "\n",
        "    def _transition_block(self, X):\n",
        "\n",
        "        X = self._conv_block(X, K.int_shape(X)[-1] //2 )\n",
        "        X = AveragePooling2D(2, strides = 2, padding = 'same')(X)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def get_model(self):\n",
        "\n",
        "        return self.model"
      ],
      "metadata": {
        "id": "XApBh--LJddY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Training the models"
      ],
      "metadata": {
        "id": "mWIj_Rs14h1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "    \"\"\"\n",
        "    Creates schedule to obtain an exponential decay of the learning rate\n",
        "    :param epoch: Int. Epoch at which we start the decay of the learning rate\n",
        "    :param lr: Float Learning rate for the optimiser\n",
        "    :return: Learning rate for a given epoch\n",
        "    \"\"\"\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return float(lr * tf.math.exp(-0.05))\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "metadata": {
        "id": "MdrkNMvA8lN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_and_fit(model_class, name):\n",
        "\n",
        "  model = model_class.get_model()\n",
        "  model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "                optimizer = 'adam',\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "  # define checkpoint callback\n",
        "  checkpoint_callback = ModelCheckpoint(\n",
        "    filepath = f'./model_saves/best_{name}.keras',\n",
        "    monitor = 'val_loss',\n",
        "    save_best_only = True,\n",
        "    mode = 'min',\n",
        "    verbose = 1\n",
        "  )\n",
        "\n",
        "  csv_logger = CSVLogger(f'csv_logs/{name}_training_log.csv', separator = ',', append = False)\n",
        "\n",
        "  history = model.fit(\n",
        "      train_ds,\n",
        "      validation_data = val_ds,\n",
        "      epochs = 50,\n",
        "      class_weight = class_weights,\n",
        "      callbacks = [checkpoint_callback, csv_logger, lr_scheduler]\n",
        "  )\n",
        "\n",
        "  return history\n",
        "\n"
      ],
      "metadata": {
        "id": "oH6JU7Sy4hRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequential = Sequential(input_shape = INPUT_SHAPE)\n",
        "history_sequential = compile_and_fit(sequential, 'sequential')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k_-skrz95oRf",
        "outputId": "b9d69967-8824-41b4-c180-927879a830e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4446 - loss: 1.8320\n",
            "Epoch 1: val_loss improved from inf to 2.04503, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - accuracy: 0.4462 - loss: 1.8281 - val_accuracy: 0.4585 - val_loss: 2.0450 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6868 - loss: 1.1676\n",
            "Epoch 2: val_loss improved from 2.04503 to 1.47333, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.6869 - loss: 1.1676 - val_accuracy: 0.5317 - val_loss: 1.4733 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7511 - loss: 0.9716\n",
            "Epoch 3: val_loss improved from 1.47333 to 0.94107, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.7514 - loss: 0.9713 - val_accuracy: 0.6293 - val_loss: 0.9411 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7754 - loss: 0.8628\n",
            "Epoch 4: val_loss improved from 0.94107 to 0.78195, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.7755 - loss: 0.8624 - val_accuracy: 0.7366 - val_loss: 0.7819 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8287 - loss: 0.6434\n",
            "Epoch 5: val_loss did not improve from 0.78195\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.8287 - loss: 0.6437 - val_accuracy: 0.7220 - val_loss: 0.8324 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8406 - loss: 0.5975\n",
            "Epoch 6: val_loss did not improve from 0.78195\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.8405 - loss: 0.5978 - val_accuracy: 0.7512 - val_loss: 0.8648 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8585 - loss: 0.5242\n",
            "Epoch 7: val_loss improved from 0.78195 to 0.70850, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.8585 - loss: 0.5244 - val_accuracy: 0.7902 - val_loss: 0.7085 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8553 - loss: 0.4934\n",
            "Epoch 8: val_loss did not improve from 0.70850\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.8552 - loss: 0.4938 - val_accuracy: 0.8000 - val_loss: 0.7155 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8658 - loss: 0.4542\n",
            "Epoch 9: val_loss improved from 0.70850 to 0.70532, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.8661 - loss: 0.4539 - val_accuracy: 0.7951 - val_loss: 0.7053 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8874 - loss: 0.3818\n",
            "Epoch 10: val_loss improved from 0.70532 to 0.44519, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.8872 - loss: 0.3821 - val_accuracy: 0.8634 - val_loss: 0.4452 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9000 - loss: 0.3511\n",
            "Epoch 11: val_loss did not improve from 0.44519\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9000 - loss: 0.3510 - val_accuracy: 0.8634 - val_loss: 0.5179 - learning_rate: 9.5123e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9078 - loss: 0.3044\n",
            "Epoch 12: val_loss did not improve from 0.44519\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9078 - loss: 0.3044 - val_accuracy: 0.8488 - val_loss: 0.4978 - learning_rate: 9.0484e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9186 - loss: 0.2791\n",
            "Epoch 13: val_loss did not improve from 0.44519\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9185 - loss: 0.2791 - val_accuracy: 0.8634 - val_loss: 0.4550 - learning_rate: 8.6071e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9157 - loss: 0.2765\n",
            "Epoch 14: val_loss improved from 0.44519 to 0.42022, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9157 - loss: 0.2765 - val_accuracy: 0.8683 - val_loss: 0.4202 - learning_rate: 8.1873e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9207 - loss: 0.2331\n",
            "Epoch 15: val_loss did not improve from 0.42022\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9208 - loss: 0.2332 - val_accuracy: 0.8683 - val_loss: 0.4233 - learning_rate: 7.7880e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9326 - loss: 0.2084\n",
            "Epoch 16: val_loss did not improve from 0.42022\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9327 - loss: 0.2085 - val_accuracy: 0.8049 - val_loss: 0.5914 - learning_rate: 7.4082e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9421 - loss: 0.1713\n",
            "Epoch 17: val_loss improved from 0.42022 to 0.41734, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9421 - loss: 0.1715 - val_accuracy: 0.8293 - val_loss: 0.4173 - learning_rate: 7.0469e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9484 - loss: 0.1763\n",
            "Epoch 18: val_loss did not improve from 0.41734\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9484 - loss: 0.1763 - val_accuracy: 0.8780 - val_loss: 0.4389 - learning_rate: 6.7032e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9500 - loss: 0.1651\n",
            "Epoch 19: val_loss did not improve from 0.41734\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9500 - loss: 0.1650 - val_accuracy: 0.8488 - val_loss: 0.4690 - learning_rate: 6.3763e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9559 - loss: 0.1473\n",
            "Epoch 20: val_loss did not improve from 0.41734\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9557 - loss: 0.1479 - val_accuracy: 0.8683 - val_loss: 0.4385 - learning_rate: 6.0653e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9440 - loss: 0.1750\n",
            "Epoch 21: val_loss improved from 0.41734 to 0.36634, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9441 - loss: 0.1749 - val_accuracy: 0.9073 - val_loss: 0.3663 - learning_rate: 5.7695e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9633 - loss: 0.1274\n",
            "Epoch 22: val_loss did not improve from 0.36634\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9633 - loss: 0.1276 - val_accuracy: 0.8634 - val_loss: 0.4136 - learning_rate: 5.4881e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9611 - loss: 0.1321\n",
            "Epoch 23: val_loss improved from 0.36634 to 0.32652, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.9611 - loss: 0.1323 - val_accuracy: 0.9122 - val_loss: 0.3265 - learning_rate: 5.2205e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9714 - loss: 0.1081\n",
            "Epoch 24: val_loss improved from 0.32652 to 0.32168, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9714 - loss: 0.1082 - val_accuracy: 0.9024 - val_loss: 0.3217 - learning_rate: 4.9659e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9787 - loss: 0.0867\n",
            "Epoch 25: val_loss improved from 0.32168 to 0.31607, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9787 - loss: 0.0868 - val_accuracy: 0.9073 - val_loss: 0.3161 - learning_rate: 4.7237e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9741 - loss: 0.0873\n",
            "Epoch 26: val_loss did not improve from 0.31607\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9741 - loss: 0.0873 - val_accuracy: 0.8732 - val_loss: 0.4122 - learning_rate: 4.4933e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9816 - loss: 0.0718\n",
            "Epoch 27: val_loss did not improve from 0.31607\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9816 - loss: 0.0718 - val_accuracy: 0.8878 - val_loss: 0.3234 - learning_rate: 4.2742e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9841 - loss: 0.0635\n",
            "Epoch 28: val_loss improved from 0.31607 to 0.30851, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9841 - loss: 0.0635 - val_accuracy: 0.8927 - val_loss: 0.3085 - learning_rate: 4.0657e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9813 - loss: 0.0643\n",
            "Epoch 29: val_loss did not improve from 0.30851\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9814 - loss: 0.0643 - val_accuracy: 0.8732 - val_loss: 0.3977 - learning_rate: 3.8674e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9878 - loss: 0.0562\n",
            "Epoch 30: val_loss improved from 0.30851 to 0.26569, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9877 - loss: 0.0563 - val_accuracy: 0.9268 - val_loss: 0.2657 - learning_rate: 3.6788e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9881 - loss: 0.0568\n",
            "Epoch 31: val_loss did not improve from 0.26569\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9881 - loss: 0.0568 - val_accuracy: 0.8927 - val_loss: 0.3373 - learning_rate: 3.4994e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9873 - loss: 0.0509\n",
            "Epoch 32: val_loss did not improve from 0.26569\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9873 - loss: 0.0509 - val_accuracy: 0.9073 - val_loss: 0.3158 - learning_rate: 3.3287e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9917 - loss: 0.0442\n",
            "Epoch 33: val_loss did not improve from 0.26569\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9917 - loss: 0.0442 - val_accuracy: 0.8976 - val_loss: 0.2863 - learning_rate: 3.1664e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9929 - loss: 0.0370\n",
            "Epoch 34: val_loss did not improve from 0.26569\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9929 - loss: 0.0370 - val_accuracy: 0.9073 - val_loss: 0.2788 - learning_rate: 3.0119e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9973 - loss: 0.0318\n",
            "Epoch 35: val_loss did not improve from 0.26569\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9973 - loss: 0.0319 - val_accuracy: 0.9024 - val_loss: 0.3112 - learning_rate: 2.8651e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9946 - loss: 0.0356\n",
            "Epoch 36: val_loss did not improve from 0.26569\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9947 - loss: 0.0356 - val_accuracy: 0.8976 - val_loss: 0.3075 - learning_rate: 2.7253e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9937 - loss: 0.0338\n",
            "Epoch 37: val_loss did not improve from 0.26569\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9936 - loss: 0.0338 - val_accuracy: 0.9122 - val_loss: 0.2814 - learning_rate: 2.5924e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9930 - loss: 0.0304\n",
            "Epoch 38: val_loss did not improve from 0.26569\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9930 - loss: 0.0304 - val_accuracy: 0.9171 - val_loss: 0.2834 - learning_rate: 2.4660e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9948 - loss: 0.0288\n",
            "Epoch 39: val_loss did not improve from 0.26569\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9948 - loss: 0.0288 - val_accuracy: 0.9122 - val_loss: 0.2784 - learning_rate: 2.3457e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9962 - loss: 0.0255\n",
            "Epoch 40: val_loss did not improve from 0.26569\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9962 - loss: 0.0255 - val_accuracy: 0.9024 - val_loss: 0.2719 - learning_rate: 2.2313e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9965 - loss: 0.0252\n",
            "Epoch 41: val_loss did not improve from 0.26569\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9965 - loss: 0.0252 - val_accuracy: 0.8878 - val_loss: 0.3307 - learning_rate: 2.1225e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9943 - loss: 0.0311\n",
            "Epoch 42: val_loss improved from 0.26569 to 0.25296, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9943 - loss: 0.0311 - val_accuracy: 0.9366 - val_loss: 0.2530 - learning_rate: 2.0190e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9974 - loss: 0.0231\n",
            "Epoch 43: val_loss did not improve from 0.25296\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9973 - loss: 0.0231 - val_accuracy: 0.9171 - val_loss: 0.2667 - learning_rate: 1.9205e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9981 - loss: 0.0205\n",
            "Epoch 44: val_loss improved from 0.25296 to 0.24799, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.9981 - loss: 0.0205 - val_accuracy: 0.9171 - val_loss: 0.2480 - learning_rate: 1.8268e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9996 - loss: 0.0167\n",
            "Epoch 45: val_loss did not improve from 0.24799\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9996 - loss: 0.0168 - val_accuracy: 0.9268 - val_loss: 0.2485 - learning_rate: 1.7377e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9991 - loss: 0.0163\n",
            "Epoch 46: val_loss did not improve from 0.24799\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9991 - loss: 0.0164 - val_accuracy: 0.9220 - val_loss: 0.2597 - learning_rate: 1.6530e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9992 - loss: 0.0169\n",
            "Epoch 47: val_loss did not improve from 0.24799\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9992 - loss: 0.0169 - val_accuracy: 0.9220 - val_loss: 0.2643 - learning_rate: 1.5724e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9986 - loss: 0.0150\n",
            "Epoch 48: val_loss did not improve from 0.24799\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9985 - loss: 0.0150 - val_accuracy: 0.9122 - val_loss: 0.2710 - learning_rate: 1.4957e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9977 - loss: 0.0155\n",
            "Epoch 49: val_loss improved from 0.24799 to 0.23890, saving model to ./model_saves/best_sequential.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.9977 - loss: 0.0155 - val_accuracy: 0.9268 - val_loss: 0.2389 - learning_rate: 1.4227e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9988 - loss: 0.0149\n",
            "Epoch 50: val_loss did not improve from 0.23890\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9987 - loss: 0.0149 - val_accuracy: 0.9220 - val_loss: 0.2448 - learning_rate: 1.3534e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = ResNet(input_shape = INPUT_SHAPE)\n",
        "history_resnet = compile_and_fit(resnet, 'resnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVpjAXSi6Ft0",
        "outputId": "306a5488-21ba-4cf0-942d-2fa5459c268e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.4884 - loss: 1.5817\n",
            "Epoch 1: val_loss improved from inf to 21.14794, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 210ms/step - accuracy: 0.4896 - loss: 1.5790 - val_accuracy: 0.2146 - val_loss: 21.1479 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.6740 - loss: 1.1059\n",
            "Epoch 2: val_loss improved from 21.14794 to 5.11909, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 0.6741 - loss: 1.1056 - val_accuracy: 0.3512 - val_loss: 5.1191 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7661 - loss: 0.9027\n",
            "Epoch 3: val_loss improved from 5.11909 to 2.50882, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 0.7659 - loss: 0.9026 - val_accuracy: 0.4439 - val_loss: 2.5088 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7738 - loss: 0.7734\n",
            "Epoch 4: val_loss improved from 2.50882 to 0.93663, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 200ms/step - accuracy: 0.7739 - loss: 0.7733 - val_accuracy: 0.6927 - val_loss: 0.9366 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8044 - loss: 0.6644\n",
            "Epoch 5: val_loss improved from 0.93663 to 0.85896, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 200ms/step - accuracy: 0.8044 - loss: 0.6648 - val_accuracy: 0.6683 - val_loss: 0.8590 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8149 - loss: 0.6170\n",
            "Epoch 6: val_loss improved from 0.85896 to 0.67678, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 200ms/step - accuracy: 0.8148 - loss: 0.6174 - val_accuracy: 0.7902 - val_loss: 0.6768 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8299 - loss: 0.5703\n",
            "Epoch 7: val_loss did not improve from 0.67678\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.8300 - loss: 0.5703 - val_accuracy: 0.7610 - val_loss: 0.7012 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8444 - loss: 0.5334\n",
            "Epoch 8: val_loss did not improve from 0.67678\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.8445 - loss: 0.5337 - val_accuracy: 0.6146 - val_loss: 0.9881 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8591 - loss: 0.4633\n",
            "Epoch 9: val_loss improved from 0.67678 to 0.55437, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 0.8591 - loss: 0.4634 - val_accuracy: 0.7902 - val_loss: 0.5544 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8730 - loss: 0.3869\n",
            "Epoch 10: val_loss improved from 0.55437 to 0.44250, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 0.8731 - loss: 0.3870 - val_accuracy: 0.8634 - val_loss: 0.4425 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9042 - loss: 0.3499\n",
            "Epoch 11: val_loss did not improve from 0.44250\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.9040 - loss: 0.3504 - val_accuracy: 0.8341 - val_loss: 0.5271 - learning_rate: 9.5123e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8962 - loss: 0.3505\n",
            "Epoch 12: val_loss did not improve from 0.44250\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.8963 - loss: 0.3504 - val_accuracy: 0.8146 - val_loss: 0.5071 - learning_rate: 9.0484e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9146 - loss: 0.2800\n",
            "Epoch 13: val_loss improved from 0.44250 to 0.43970, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 0.9146 - loss: 0.2804 - val_accuracy: 0.8732 - val_loss: 0.4397 - learning_rate: 8.6071e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9159 - loss: 0.2662\n",
            "Epoch 14: val_loss improved from 0.43970 to 0.32905, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 0.9159 - loss: 0.2662 - val_accuracy: 0.8829 - val_loss: 0.3291 - learning_rate: 8.1873e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9281 - loss: 0.2354\n",
            "Epoch 15: val_loss did not improve from 0.32905\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.9280 - loss: 0.2355 - val_accuracy: 0.8829 - val_loss: 0.3686 - learning_rate: 7.7880e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9322 - loss: 0.2186\n",
            "Epoch 16: val_loss improved from 0.32905 to 0.31397, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 0.9322 - loss: 0.2187 - val_accuracy: 0.8878 - val_loss: 0.3140 - learning_rate: 7.4082e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9424 - loss: 0.1841\n",
            "Epoch 17: val_loss did not improve from 0.31397\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9424 - loss: 0.1844 - val_accuracy: 0.8878 - val_loss: 0.3399 - learning_rate: 7.0469e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9467 - loss: 0.1753\n",
            "Epoch 18: val_loss did not improve from 0.31397\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.9467 - loss: 0.1754 - val_accuracy: 0.8927 - val_loss: 0.3209 - learning_rate: 6.7032e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9517 - loss: 0.1588\n",
            "Epoch 19: val_loss improved from 0.31397 to 0.26737, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 0.9518 - loss: 0.1588 - val_accuracy: 0.9024 - val_loss: 0.2674 - learning_rate: 6.3763e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9606 - loss: 0.1254\n",
            "Epoch 20: val_loss improved from 0.26737 to 0.22554, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 0.9606 - loss: 0.1255 - val_accuracy: 0.9268 - val_loss: 0.2255 - learning_rate: 6.0653e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9754 - loss: 0.1150\n",
            "Epoch 21: val_loss did not improve from 0.22554\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9754 - loss: 0.1152 - val_accuracy: 0.9171 - val_loss: 0.2391 - learning_rate: 5.7695e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9712 - loss: 0.1129\n",
            "Epoch 22: val_loss did not improve from 0.22554\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9712 - loss: 0.1131 - val_accuracy: 0.9171 - val_loss: 0.2631 - learning_rate: 5.4881e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9727 - loss: 0.1090\n",
            "Epoch 23: val_loss did not improve from 0.22554\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9727 - loss: 0.1091 - val_accuracy: 0.8488 - val_loss: 0.4040 - learning_rate: 5.2205e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9726 - loss: 0.1012\n",
            "Epoch 24: val_loss did not improve from 0.22554\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9726 - loss: 0.1011 - val_accuracy: 0.8927 - val_loss: 0.2773 - learning_rate: 4.9659e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9832 - loss: 0.0717\n",
            "Epoch 25: val_loss did not improve from 0.22554\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9833 - loss: 0.0718 - val_accuracy: 0.9073 - val_loss: 0.2343 - learning_rate: 4.7237e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9828 - loss: 0.0630\n",
            "Epoch 26: val_loss did not improve from 0.22554\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9829 - loss: 0.0630 - val_accuracy: 0.8976 - val_loss: 0.2409 - learning_rate: 4.4933e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9862 - loss: 0.0572\n",
            "Epoch 27: val_loss improved from 0.22554 to 0.17626, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 0.9862 - loss: 0.0573 - val_accuracy: 0.9317 - val_loss: 0.1763 - learning_rate: 4.2742e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9910 - loss: 0.0465\n",
            "Epoch 28: val_loss did not improve from 0.17626\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9910 - loss: 0.0466 - val_accuracy: 0.9024 - val_loss: 0.2362 - learning_rate: 4.0657e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9864 - loss: 0.0535\n",
            "Epoch 29: val_loss improved from 0.17626 to 0.15589, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 201ms/step - accuracy: 0.9864 - loss: 0.0534 - val_accuracy: 0.9463 - val_loss: 0.1559 - learning_rate: 3.8674e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9960 - loss: 0.0342\n",
            "Epoch 30: val_loss did not improve from 0.15589\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9960 - loss: 0.0343 - val_accuracy: 0.9220 - val_loss: 0.2163 - learning_rate: 3.6788e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9910 - loss: 0.0390\n",
            "Epoch 31: val_loss did not improve from 0.15589\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9910 - loss: 0.0391 - val_accuracy: 0.9415 - val_loss: 0.1785 - learning_rate: 3.4994e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9916 - loss: 0.0356\n",
            "Epoch 32: val_loss did not improve from 0.15589\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.9917 - loss: 0.0356 - val_accuracy: 0.9415 - val_loss: 0.1598 - learning_rate: 3.3287e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9941 - loss: 0.0338\n",
            "Epoch 33: val_loss did not improve from 0.15589\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.9941 - loss: 0.0338 - val_accuracy: 0.9366 - val_loss: 0.1868 - learning_rate: 3.1664e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9934 - loss: 0.0334\n",
            "Epoch 34: val_loss did not improve from 0.15589\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9934 - loss: 0.0335 - val_accuracy: 0.9024 - val_loss: 0.1951 - learning_rate: 3.0119e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9985 - loss: 0.0275\n",
            "Epoch 35: val_loss improved from 0.15589 to 0.15467, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 0.9985 - loss: 0.0275 - val_accuracy: 0.9463 - val_loss: 0.1547 - learning_rate: 2.8651e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9966 - loss: 0.0242\n",
            "Epoch 36: val_loss did not improve from 0.15467\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.9966 - loss: 0.0242 - val_accuracy: 0.9366 - val_loss: 0.1835 - learning_rate: 2.7253e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9963 - loss: 0.0237\n",
            "Epoch 37: val_loss did not improve from 0.15467\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9963 - loss: 0.0237 - val_accuracy: 0.9366 - val_loss: 0.1611 - learning_rate: 2.5924e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9956 - loss: 0.0211\n",
            "Epoch 38: val_loss did not improve from 0.15467\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.9957 - loss: 0.0211 - val_accuracy: 0.9561 - val_loss: 0.1555 - learning_rate: 2.4660e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9992 - loss: 0.0179\n",
            "Epoch 39: val_loss improved from 0.15467 to 0.13869, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 200ms/step - accuracy: 0.9992 - loss: 0.0179 - val_accuracy: 0.9463 - val_loss: 0.1387 - learning_rate: 2.3457e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9955 - loss: 0.0275\n",
            "Epoch 40: val_loss improved from 0.13869 to 0.13067, saving model to ./model_saves/best_resnet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 202ms/step - accuracy: 0.9955 - loss: 0.0275 - val_accuracy: 0.9659 - val_loss: 0.1307 - learning_rate: 2.2313e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9988 - loss: 0.0163\n",
            "Epoch 41: val_loss did not improve from 0.13067\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.9988 - loss: 0.0164 - val_accuracy: 0.9659 - val_loss: 0.1332 - learning_rate: 2.1225e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9978 - loss: 0.0179\n",
            "Epoch 42: val_loss did not improve from 0.13067\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9978 - loss: 0.0180 - val_accuracy: 0.9512 - val_loss: 0.1721 - learning_rate: 2.0190e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9963 - loss: 0.0223\n",
            "Epoch 43: val_loss did not improve from 0.13067\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.9963 - loss: 0.0223 - val_accuracy: 0.9512 - val_loss: 0.1597 - learning_rate: 1.9205e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9979 - loss: 0.0167\n",
            "Epoch 44: val_loss did not improve from 0.13067\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.9979 - loss: 0.0167 - val_accuracy: 0.9659 - val_loss: 0.1469 - learning_rate: 1.8268e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9989 - loss: 0.0144\n",
            "Epoch 45: val_loss did not improve from 0.13067\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.9989 - loss: 0.0144 - val_accuracy: 0.9659 - val_loss: 0.1438 - learning_rate: 1.7377e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9991 - loss: 0.0137\n",
            "Epoch 46: val_loss did not improve from 0.13067\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.9991 - loss: 0.0137 - val_accuracy: 0.9756 - val_loss: 0.1382 - learning_rate: 1.6530e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9992 - loss: 0.0126\n",
            "Epoch 47: val_loss did not improve from 0.13067\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 0.9992 - loss: 0.0126 - val_accuracy: 0.9610 - val_loss: 0.1431 - learning_rate: 1.5724e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9996 - loss: 0.0118\n",
            "Epoch 48: val_loss did not improve from 0.13067\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 187ms/step - accuracy: 0.9996 - loss: 0.0118 - val_accuracy: 0.9610 - val_loss: 0.1459 - learning_rate: 1.4957e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 1.0000 - loss: 0.0119\n",
            "Epoch 49: val_loss did not improve from 0.13067\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 186ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.9512 - val_loss: 0.1415 - learning_rate: 1.4227e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.9992 - loss: 0.0114\n",
            "Epoch 50: val_loss did not improve from 0.13067\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 185ms/step - accuracy: 0.9992 - loss: 0.0114 - val_accuracy: 0.9610 - val_loss: 0.1442 - learning_rate: 1.3534e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "densenet = DenseNet(input_shape = INPUT_SHAPE)\n",
        "history_densenet = compile_and_fit(densenet, 'densenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I39aZJ_66KkT",
        "outputId": "2c0c5571-4f87-4fbb-98e5-feec95b80b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.4353 - loss: 1.6463\n",
            "Epoch 1: val_loss improved from inf to 61.84329, saving model to ./model_saves/best_densenet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 289ms/step - accuracy: 0.4374 - loss: 1.6433 - val_accuracy: 0.1512 - val_loss: 61.8433 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.7064 - loss: 1.1307\n",
            "Epoch 2: val_loss improved from 61.84329 to 8.67159, saving model to ./model_saves/best_densenet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 226ms/step - accuracy: 0.7063 - loss: 1.1307 - val_accuracy: 0.2585 - val_loss: 8.6716 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.7060 - loss: 1.0302\n",
            "Epoch 3: val_loss did not improve from 8.67159\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 196ms/step - accuracy: 0.7060 - loss: 1.0299 - val_accuracy: 0.3073 - val_loss: 9.2025 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.7213 - loss: 0.8992\n",
            "Epoch 4: val_loss improved from 8.67159 to 4.26361, saving model to ./model_saves/best_densenet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 227ms/step - accuracy: 0.7214 - loss: 0.8995 - val_accuracy: 0.3317 - val_loss: 4.2636 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.7384 - loss: 0.8546\n",
            "Epoch 5: val_loss improved from 4.26361 to 0.82205, saving model to ./model_saves/best_densenet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 225ms/step - accuracy: 0.7384 - loss: 0.8549 - val_accuracy: 0.7220 - val_loss: 0.8221 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.7592 - loss: 0.8149\n",
            "Epoch 6: val_loss did not improve from 0.82205\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.7592 - loss: 0.8150 - val_accuracy: 0.6927 - val_loss: 1.2578 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.7774 - loss: 0.7494\n",
            "Epoch 7: val_loss did not improve from 0.82205\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.7774 - loss: 0.7496 - val_accuracy: 0.6537 - val_loss: 1.0147 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.8054 - loss: 0.6517\n",
            "Epoch 8: val_loss did not improve from 0.82205\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.8054 - loss: 0.6521 - val_accuracy: 0.6780 - val_loss: 0.9237 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.8119 - loss: 0.6139\n",
            "Epoch 9: val_loss did not improve from 0.82205\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.8119 - loss: 0.6143 - val_accuracy: 0.6585 - val_loss: 1.0832 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.8369 - loss: 0.5733\n",
            "Epoch 10: val_loss improved from 0.82205 to 0.75489, saving model to ./model_saves/best_densenet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 225ms/step - accuracy: 0.8369 - loss: 0.5738 - val_accuracy: 0.7707 - val_loss: 0.7549 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.8553 - loss: 0.5104\n",
            "Epoch 11: val_loss did not improve from 0.75489\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.8551 - loss: 0.5111 - val_accuracy: 0.6780 - val_loss: 0.9446 - learning_rate: 9.5123e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.8400 - loss: 0.5217\n",
            "Epoch 12: val_loss improved from 0.75489 to 0.53008, saving model to ./model_saves/best_densenet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 227ms/step - accuracy: 0.8401 - loss: 0.5219 - val_accuracy: 0.7951 - val_loss: 0.5301 - learning_rate: 9.0484e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.8417 - loss: 0.4709\n",
            "Epoch 13: val_loss did not improve from 0.53008\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.8419 - loss: 0.4711 - val_accuracy: 0.7756 - val_loss: 0.6993 - learning_rate: 8.6071e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.8620 - loss: 0.4348\n",
            "Epoch 14: val_loss did not improve from 0.53008\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 194ms/step - accuracy: 0.8621 - loss: 0.4354 - val_accuracy: 0.7902 - val_loss: 0.6231 - learning_rate: 8.1873e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.8723 - loss: 0.4078\n",
            "Epoch 15: val_loss did not improve from 0.53008\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 195ms/step - accuracy: 0.8723 - loss: 0.4082 - val_accuracy: 0.8146 - val_loss: 0.5329 - learning_rate: 7.7880e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.8873 - loss: 0.3516\n",
            "Epoch 16: val_loss improved from 0.53008 to 0.41330, saving model to ./model_saves/best_densenet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 226ms/step - accuracy: 0.8874 - loss: 0.3519 - val_accuracy: 0.8488 - val_loss: 0.4133 - learning_rate: 7.4082e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.8892 - loss: 0.3309\n",
            "Epoch 17: val_loss did not improve from 0.41330\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 196ms/step - accuracy: 0.8893 - loss: 0.3310 - val_accuracy: 0.8390 - val_loss: 0.4751 - learning_rate: 7.0469e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9128 - loss: 0.2887\n",
            "Epoch 18: val_loss improved from 0.41330 to 0.40456, saving model to ./model_saves/best_densenet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 228ms/step - accuracy: 0.9127 - loss: 0.2890 - val_accuracy: 0.8634 - val_loss: 0.4046 - learning_rate: 6.7032e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9022 - loss: 0.2859\n",
            "Epoch 19: val_loss did not improve from 0.40456\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.9023 - loss: 0.2861 - val_accuracy: 0.8585 - val_loss: 0.4381 - learning_rate: 6.3763e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9097 - loss: 0.2725\n",
            "Epoch 20: val_loss did not improve from 0.40456\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.9096 - loss: 0.2730 - val_accuracy: 0.8390 - val_loss: 0.4210 - learning_rate: 6.0653e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9202 - loss: 0.2724\n",
            "Epoch 21: val_loss did not improve from 0.40456\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.9202 - loss: 0.2725 - val_accuracy: 0.8195 - val_loss: 0.4956 - learning_rate: 5.7695e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.9312 - loss: 0.2235\n",
            "Epoch 22: val_loss did not improve from 0.40456\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 194ms/step - accuracy: 0.9311 - loss: 0.2239 - val_accuracy: 0.7366 - val_loss: 0.7401 - learning_rate: 5.4881e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9369 - loss: 0.2050\n",
            "Epoch 23: val_loss did not improve from 0.40456\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 189ms/step - accuracy: 0.9369 - loss: 0.2054 - val_accuracy: 0.8293 - val_loss: 0.5437 - learning_rate: 5.2205e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.9134 - loss: 0.2429\n",
            "Epoch 24: val_loss improved from 0.40456 to 0.40316, saving model to ./model_saves/best_densenet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 218ms/step - accuracy: 0.9134 - loss: 0.2430 - val_accuracy: 0.8927 - val_loss: 0.4032 - learning_rate: 4.9659e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9221 - loss: 0.2198\n",
            "Epoch 25: val_loss did not improve from 0.40316\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 191ms/step - accuracy: 0.9222 - loss: 0.2200 - val_accuracy: 0.8195 - val_loss: 0.4818 - learning_rate: 4.7237e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9398 - loss: 0.1785\n",
            "Epoch 26: val_loss did not improve from 0.40316\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 191ms/step - accuracy: 0.9398 - loss: 0.1789 - val_accuracy: 0.8390 - val_loss: 0.5094 - learning_rate: 4.4933e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9467 - loss: 0.1562\n",
            "Epoch 27: val_loss improved from 0.40316 to 0.35461, saving model to ./model_saves/best_densenet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 219ms/step - accuracy: 0.9467 - loss: 0.1563 - val_accuracy: 0.8634 - val_loss: 0.3546 - learning_rate: 4.2742e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9532 - loss: 0.1416\n",
            "Epoch 28: val_loss improved from 0.35461 to 0.28254, saving model to ./model_saves/best_densenet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 222ms/step - accuracy: 0.9531 - loss: 0.1419 - val_accuracy: 0.9122 - val_loss: 0.2825 - learning_rate: 4.0657e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9413 - loss: 0.1822\n",
            "Epoch 29: val_loss did not improve from 0.28254\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.9413 - loss: 0.1822 - val_accuracy: 0.8829 - val_loss: 0.3604 - learning_rate: 3.8674e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9695 - loss: 0.1055\n",
            "Epoch 30: val_loss did not improve from 0.28254\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 196ms/step - accuracy: 0.9695 - loss: 0.1056 - val_accuracy: 0.8878 - val_loss: 0.3351 - learning_rate: 3.6788e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9642 - loss: 0.1188\n",
            "Epoch 31: val_loss did not improve from 0.28254\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.9642 - loss: 0.1189 - val_accuracy: 0.8829 - val_loss: 0.3301 - learning_rate: 3.4994e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9635 - loss: 0.1163\n",
            "Epoch 32: val_loss did not improve from 0.28254\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.9635 - loss: 0.1163 - val_accuracy: 0.8829 - val_loss: 0.3911 - learning_rate: 3.3287e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9708 - loss: 0.0978\n",
            "Epoch 33: val_loss did not improve from 0.28254\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 196ms/step - accuracy: 0.9708 - loss: 0.0978 - val_accuracy: 0.8780 - val_loss: 0.3834 - learning_rate: 3.1664e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9701 - loss: 0.0918\n",
            "Epoch 34: val_loss did not improve from 0.28254\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 196ms/step - accuracy: 0.9701 - loss: 0.0918 - val_accuracy: 0.8976 - val_loss: 0.3029 - learning_rate: 3.0119e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9809 - loss: 0.0704\n",
            "Epoch 35: val_loss did not improve from 0.28254\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 196ms/step - accuracy: 0.9809 - loss: 0.0705 - val_accuracy: 0.9122 - val_loss: 0.3396 - learning_rate: 2.8651e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9821 - loss: 0.0621\n",
            "Epoch 36: val_loss did not improve from 0.28254\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 196ms/step - accuracy: 0.9821 - loss: 0.0622 - val_accuracy: 0.9073 - val_loss: 0.3457 - learning_rate: 2.7253e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9833 - loss: 0.0575\n",
            "Epoch 37: val_loss did not improve from 0.28254\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.9833 - loss: 0.0576 - val_accuracy: 0.8927 - val_loss: 0.3652 - learning_rate: 2.5924e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9876 - loss: 0.0529\n",
            "Epoch 38: val_loss did not improve from 0.28254\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.9876 - loss: 0.0529 - val_accuracy: 0.9122 - val_loss: 0.3232 - learning_rate: 2.4660e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9826 - loss: 0.0639\n",
            "Epoch 39: val_loss did not improve from 0.28254\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 196ms/step - accuracy: 0.9826 - loss: 0.0641 - val_accuracy: 0.8976 - val_loss: 0.3406 - learning_rate: 2.3457e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9814 - loss: 0.0672\n",
            "Epoch 40: val_loss improved from 0.28254 to 0.27371, saving model to ./model_saves/best_densenet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 225ms/step - accuracy: 0.9814 - loss: 0.0672 - val_accuracy: 0.9073 - val_loss: 0.2737 - learning_rate: 2.2313e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.9887 - loss: 0.0479\n",
            "Epoch 41: val_loss did not improve from 0.27371\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 199ms/step - accuracy: 0.9887 - loss: 0.0480 - val_accuracy: 0.9024 - val_loss: 0.3255 - learning_rate: 2.1225e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9916 - loss: 0.0413\n",
            "Epoch 42: val_loss did not improve from 0.27371\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 198ms/step - accuracy: 0.9915 - loss: 0.0415 - val_accuracy: 0.8976 - val_loss: 0.3522 - learning_rate: 2.0190e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.9892 - loss: 0.0535\n",
            "Epoch 43: val_loss did not improve from 0.27371\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.9892 - loss: 0.0537 - val_accuracy: 0.8537 - val_loss: 0.5236 - learning_rate: 1.9205e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9849 - loss: 0.0550\n",
            "Epoch 44: val_loss did not improve from 0.27371\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 195ms/step - accuracy: 0.9849 - loss: 0.0550 - val_accuracy: 0.8829 - val_loss: 0.3976 - learning_rate: 1.8268e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9875 - loss: 0.0419\n",
            "Epoch 45: val_loss did not improve from 0.27371\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 195ms/step - accuracy: 0.9875 - loss: 0.0419 - val_accuracy: 0.9122 - val_loss: 0.3262 - learning_rate: 1.7377e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.9918 - loss: 0.0372\n",
            "Epoch 46: val_loss did not improve from 0.27371\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 197ms/step - accuracy: 0.9918 - loss: 0.0372 - val_accuracy: 0.9122 - val_loss: 0.3531 - learning_rate: 1.6530e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9955 - loss: 0.0290\n",
            "Epoch 47: val_loss did not improve from 0.27371\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 198ms/step - accuracy: 0.9955 - loss: 0.0291 - val_accuracy: 0.9024 - val_loss: 0.3036 - learning_rate: 1.5724e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.9955 - loss: 0.0248\n",
            "Epoch 48: val_loss did not improve from 0.27371\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 198ms/step - accuracy: 0.9955 - loss: 0.0248 - val_accuracy: 0.9122 - val_loss: 0.2942 - learning_rate: 1.4957e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.9968 - loss: 0.0239\n",
            "Epoch 49: val_loss improved from 0.27371 to 0.26937, saving model to ./model_saves/best_densenet.keras\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 226ms/step - accuracy: 0.9968 - loss: 0.0239 - val_accuracy: 0.9073 - val_loss: 0.2694 - learning_rate: 1.4227e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9991 - loss: 0.0204\n",
            "Epoch 50: val_loss did not improve from 0.26937\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 189ms/step - accuracy: 0.9991 - loss: 0.0204 - val_accuracy: 0.9122 - val_loss: 0.2873 - learning_rate: 1.3534e-04\n"
          ]
        }
      ]
    }
  ]
}